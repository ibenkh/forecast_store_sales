{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d09c324d-5c77-4851-8d8f-07a89fb0be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48d9339c-9936-453c-8b68-099890e0ddf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_id</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>bu</th>\n",
       "      <th>famid</th>\n",
       "      <th>sales</th>\n",
       "      <th>onprom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>3564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>5346</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>7128</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>8910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ts_id       date    id  bu  famid  sales  onprom\n",
       "0   1_0 2013-01-02  1782   1      0    2.0       0\n",
       "1   1_0 2013-01-03  3564   1      0    3.0       0\n",
       "2   1_0 2013-01-04  5346   1      0    3.0       0\n",
       "3   1_0 2013-01-05  7128   1      0    5.0       0\n",
       "4   1_0 2013-01-06  8910   1      0    2.0       0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/idris/Documents/ds_project/forecast_store_sales/'\n",
    "df_train = pd.read_csv(path + '/data/trainclean.csv', sep=';')\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_test = pd.read_csv(path + '/data/testclean.csv', sep=';')\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "\n",
    "df = pd.concat([df_train, df_test], axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cf4fd9c-805b-4a21-9771-47f0c39e2b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>bu</th>\n",
       "      <th>transactions</th>\n",
       "      <th>isclosed</th>\n",
       "      <th>typeid</th>\n",
       "      <th>cityid</th>\n",
       "      <th>stateid</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2111.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1863.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>520.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  bu  transactions  isclosed  typeid  cityid  stateid  cluster\n",
       "0 2013-01-02   1        2111.0         0       0       0        0       13\n",
       "1 2013-01-03   1        1833.0         0       0       0        0       13\n",
       "2 2013-01-04   1        1863.0         0       0       0        0       13\n",
       "3 2013-01-05   1        1509.0         0       0       0        0       13\n",
       "4 2013-01-06   1         520.0         0       0       0        0       13"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f_d = df[['date']].drop_duplicates()\n",
    "df_f_d['day'] = df_f_d['date'].dt.day\n",
    "df_f_d['week'] = df_f_d['date'].dt.isocalendar().week\n",
    "df_f_d['month'] = df_f_d['date'].dt.month\n",
    "df_f_d['year'] = df_f_d['date'].dt.year\n",
    "df_f_d['yearmoment'] = (df_f_d['year'] - df_f_d['year'].min())\n",
    "df_f_d['weekofmonth'] = df_f_d['day'].apply(lambda x: np.ceil(x/7))\n",
    "\n",
    "df_f_d['dayofweek'] = df_f_d['date'].dt.dayofweek\n",
    "df_f_d['weekend'] = (df_f_d['dayofweek']>=5)\n",
    "\n",
    "df_f_d['cosweek'] = np.cos(df_f_d['week'])\n",
    "df_f_d['sinweek'] = np.sin(df_f_d['week'])\n",
    "\n",
    "df_f_d.tail()\n",
    "\n",
    "df_hol_event = pd.read_csv(path + '/data/holidays_events.csv')\n",
    "hol_ev_keep = ['Holiday', 'Additional', 'Event']\n",
    "df_hol_event = df_hol_event[df_hol_event['type'].isin(hol_ev_keep)][['date']]\n",
    "df_hol_event['date'] = pd.to_datetime(df_hol_event['date'])\n",
    "df_hol_event = df_hol_event.drop_duplicates()\n",
    "\n",
    "df_hol_event['hol'] = 1\n",
    "\n",
    "df_f_d_h = df_f_d.merge(df_hol_event, on=['date'], how='left')\n",
    "df_f_d_h['hol'] = df_f_d_h['hol'].fillna(0).astype(int)\n",
    "df_f_d_h['hol_before_1'] = df_f_d_h['hol'].shift(1).fillna(0).astype(int)\n",
    "df_f_d_h['hol_before_2'] = df_f_d_h['hol'].shift(2).fillna(0).astype(int)\n",
    "df_f_d_h['hol_before_3'] = df_f_d_h['hol'].shift(3).fillna(0).astype(int)\n",
    "df_f_d_h['hol_after_1'] = df_f_d_h['hol'].shift(-1).fillna(0).astype(int)\n",
    "\n",
    "df_f_d_h.head()\n",
    "\n",
    "df_oil = pd.read_csv(path + '/data/oil.csv')\n",
    "df_oil['date'] = pd.to_datetime(df_oil['date'])\n",
    "df_oil.columns = ['date', 'prixoil']\n",
    "df_f_d_h_o = df_f_d_h.merge(df_oil, on=['date'], how='left')\n",
    "df_f_d_h_o['prixoil'] = df_f_d_h_o['prixoil'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "df_f_d_h_o.to_csv('data/fe/date_holidays_oil.csv', index=False, sep=';')\n",
    "df_f_d_h_o.head()\n",
    "\n",
    "\n",
    "df_store = pd.read_csv(path + '/data/stores.csv')\n",
    "\n",
    "df_store['typeid'] = pd.factorize(df_store['type'])[0]\n",
    "df_store['cityid'] = pd.factorize(df_store['city'])[0]\n",
    "df_store['stateid'] = pd.factorize(df_store['state'])[0]\n",
    "\n",
    "df_store_infos = df_store[['store_nbr', 'city', 'state', 'type', 'typeid', 'cityid', 'stateid', 'cluster']].drop_duplicates()\n",
    "df_store_infos.to_csv('data/df_store_infos.csv', index=False, sep=';')\n",
    "\n",
    "df_transaction = pd.read_csv(path + '/data/transactions.csv')\n",
    "df_transaction.columns = ['date', 'bu', 'transactions']\n",
    "df_transaction['date'] = pd.to_datetime(df_transaction['date'])\n",
    "\n",
    "df_store_transactions = df[['date', 'bu']].drop_duplicates() \\\n",
    "    .merge(df_transaction, how='left', on=['date', 'bu'])\n",
    "\n",
    "df_store_transactions['transactions'] = df_store_transactions['transactions'].fillna(0)\n",
    "\n",
    "df_store_transactions_hol = df_store_transactions.merge(df_f_d_h[['date', 'hol']], on=['date'], how='left')\n",
    "df_store_transactions_hol['isclosed'] = 0\n",
    "df_store_transactions_hol.loc[(df_store_transactions_hol['hol'] == 1) & (df_store_transactions_hol['transactions'] == 0),\n",
    "                              'isclosed'] = 1\n",
    "\n",
    "df_store_transactions = df_store_transactions_hol.drop('hol', axis=1)\n",
    "\n",
    "df_store = df_store[['store_nbr', 'typeid', 'cityid', 'stateid', 'cluster']]\n",
    "df_store.columns = ['bu', 'typeid', 'cityid', 'stateid', 'cluster']\n",
    "\n",
    "df_store_transactions = df_store_transactions.merge(df_store, how='left', on=['bu'])\n",
    "df_store_transactions = df_store_transactions.drop_duplicates()\n",
    "df_store_transactions.to_csv('data/fe/stores_details_transactions.csv', index=False, sep=';')\n",
    "\n",
    "df_store_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb3243e2-2258-4787-8ff6-285353c0525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lags(df, col, lags, shift=0):\n",
    "    for l in lags:\n",
    "        df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
    "\n",
    "def calculate_rollings(df, col, rollings, shift=0):\n",
    "    for r in rollings:\n",
    "        df[f\"rol_mean_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).mean()\n",
    "        df[f\"rol_std_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).std()\n",
    "        df[f\"rol_min_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).min()\n",
    "        df[f\"rol_max_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).max()\n",
    "\n",
    "def calculate_agg(df, agg_col, group_col):\n",
    "    group_col_name = \"_\".join(group_col)\n",
    "    df[f\"mean_{agg_col}_by_{group_col_name}\"] = df.groupby(group_col)[agg_col].transform(\"mean\")\n",
    "    df[f\"std_{agg_col}_by_{group_col_name}\"] = df.groupby(group_col)[agg_col].transform(\"std\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c9eda1c-8697-4925-8ef1-10c4d456f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags_target=list(range(1, 104))\n",
    "rollings_target=[2, 4, 8, 16, 26, 52, 104]\n",
    "\n",
    "horizon = 16\n",
    "\n",
    "TARGET_COL = \"sales\"\n",
    "\n",
    "agg_cols =  [\n",
    "            ['stateid'],\n",
    "            ['bu'],\n",
    "            ['cityid'],\n",
    "            ['famid'],\n",
    "            ['stateid', 'famid'],\n",
    "            ['stateid', 'cityid'],\n",
    "            ['stateid', 'cluster'],\n",
    "            ['cluster', 'bu'],\n",
    "            ['cluster']\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de586e04-cfa2-4026-835d-03ebdbf491e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cutoff = ['2017-07-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "baeb5f08-8954-4e96-b20e-cce3e0a3bd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31\n",
      "2017-08-15 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"lag_{col}_{l}\"] = df.groupby([\"ts_id\"])[col].shift(shift + l).astype(np.float16)\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_mean_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).mean()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_std_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).std()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_min_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).min()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_max_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).max()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_mean_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).mean()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_std_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).std()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_min_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).min()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_max_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).max()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_mean_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).mean()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_std_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).std()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_min_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).min()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_max_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).max()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_mean_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).mean()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_std_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).std()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_min_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).min()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_max_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).max()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_mean_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).mean()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_std_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).std()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_min_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).min()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_max_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).max()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_mean_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).mean()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_std_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).std()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_min_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).min()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_max_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).max()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_mean_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).mean()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_std_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).std()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_min_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).min()\n",
      "/var/folders/4n/2ycm0xd14jgb1blvw6f3mzvr0000gn/T/ipykernel_939/104598143.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"rol_max_{col}_{r}\"] = df.groupby([\"ts_id\"])[col].shift(shift + 1).rolling(r, min_periods=1).max()\n",
      "100%|████████████████████████████████████████████| 1/1 [02:28<00:00, 148.58s/it]\n"
     ]
    }
   ],
   "source": [
    "for cutoff in tqdm(list_cutoff):\n",
    "    \n",
    "    print(cutoff)\n",
    "    d_cutoff = pd.to_datetime(cutoff)\n",
    "    day_max = d_cutoff +  datetime.timedelta(days=horizon -1)\n",
    "    df_cutoff = df[df['date'] <= day_max]\n",
    "    df_cutoff.loc[df_cutoff['date'] >= d_cutoff, 'sales'] = np.NaN\n",
    "    print(df_cutoff.date.max())\n",
    "    \n",
    "    outdir = path + f'/data/fe/cutoff/{cutoff}'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    df_cutoff.to_csv(f'data/fe/cutoff/{cutoff}/sales_cutoff.csv', index=False, sep=';')\n",
    "    \n",
    "    sales_df = df_cutoff[['ts_id', 'bu', 'famid','date', 'sales']]\n",
    "    \n",
    "    calculate_lags(sales_df, TARGET_COL, lags_target)\n",
    "    calculate_rollings(sales_df, TARGET_COL, rollings_target)\n",
    "    \n",
    "    sales_df = sales_df.merge(df_store_transactions[['date', 'bu', 'cityid', 'stateid', 'cluster']],\n",
    "                              how='left', on=['date', 'bu'])\n",
    "    \n",
    "    for group_col in agg_cols:\n",
    "        calculate_agg(sales_df, TARGET_COL, group_col)\n",
    "    \n",
    "    \n",
    "    sales_df = sales_df.drop(['bu', 'famid', 'cityid', 'stateid', 'cluster'], axis=1)\n",
    "    sales_df[\"is_future\"] = sales_df[\"sales\"].isnull()\n",
    "\n",
    "    # reduce df_features droping NA in the past\n",
    "    sales_df = pd.concat([\n",
    "        sales_df[~sales_df[\"is_future\"]].dropna(),\n",
    "        sales_df[sales_df[\"is_future\"]]\n",
    "    ])\n",
    "\n",
    "    sales_df[\"time_idx\"] = ((sales_df[\"date\"] - sales_df[\"date\"].min()).dt.days).astype(int)\n",
    "\n",
    "    first_future_time_idx = sales_df.loc[sales_df[\"is_future\"], \"time_idx\"].min()\n",
    "    sales_df[\"forecast_step\"] = sales_df[\"time_idx\"] - first_future_time_idx + 1\n",
    "    \n",
    "    sales_df.to_csv(f'data/fe/cutoff/{cutoff}/df_festures.csv', index=False, sep=';')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a53bf0e-cfb2-40ec-b084-5c858afb66ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>lag_sales_1</th>\n",
       "      <th>lag_sales_2</th>\n",
       "      <th>lag_sales_3</th>\n",
       "      <th>lag_sales_4</th>\n",
       "      <th>lag_sales_5</th>\n",
       "      <th>lag_sales_6</th>\n",
       "      <th>lag_sales_7</th>\n",
       "      <th>...</th>\n",
       "      <th>std_sales_by_stateid_cityid</th>\n",
       "      <th>mean_sales_by_stateid_cluster</th>\n",
       "      <th>std_sales_by_stateid_cluster</th>\n",
       "      <th>mean_sales_by_cluster_bu</th>\n",
       "      <th>std_sales_by_cluster_bu</th>\n",
       "      <th>mean_sales_by_cluster</th>\n",
       "      <th>std_sales_by_cluster</th>\n",
       "      <th>is_future</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>forecast_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-04-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-04-16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-04-17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>-1565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-04-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>-1564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2013-04-19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>-1563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ts_id       date  sales  lag_sales_1  lag_sales_2  lag_sales_3  \\\n",
       "103   1_0 2013-04-15    1.0          0.0          0.0          3.0   \n",
       "104   1_0 2013-04-16    3.0          1.0          0.0          0.0   \n",
       "105   1_0 2013-04-17    4.0          3.0          1.0          0.0   \n",
       "106   1_0 2013-04-18    0.0          4.0          3.0          1.0   \n",
       "107   1_0 2013-04-19    4.0          0.0          4.0          3.0   \n",
       "\n",
       "     lag_sales_4  lag_sales_5  lag_sales_6  lag_sales_7  ...  \\\n",
       "103          5.0          3.0          4.0          3.0  ...   \n",
       "104          3.0          5.0          3.0          4.0  ...   \n",
       "105          0.0          3.0          5.0          3.0  ...   \n",
       "106          0.0          0.0          3.0          5.0  ...   \n",
       "107          1.0          0.0          0.0          3.0  ...   \n",
       "\n",
       "     std_sales_by_stateid_cityid  mean_sales_by_stateid_cluster  \\\n",
       "103                  1662.976645                     413.425163   \n",
       "104                  1662.976645                     413.425163   \n",
       "105                  1662.976645                     413.425163   \n",
       "106                  1662.976645                     413.425163   \n",
       "107                  1662.976645                     413.425163   \n",
       "\n",
       "     std_sales_by_stateid_cluster  mean_sales_by_cluster_bu  \\\n",
       "103                    998.959234                288.148076   \n",
       "104                    998.959234                288.148076   \n",
       "105                    998.959234                288.148076   \n",
       "106                    998.959234                288.148076   \n",
       "107                    998.959234                288.148076   \n",
       "\n",
       "     std_sales_by_cluster_bu  mean_sales_by_cluster  std_sales_by_cluster  \\\n",
       "103               626.985139              391.75253            950.365401   \n",
       "104               626.985139              391.75253            950.365401   \n",
       "105               626.985139              391.75253            950.365401   \n",
       "106               626.985139              391.75253            950.365401   \n",
       "107               626.985139              391.75253            950.365401   \n",
       "\n",
       "     is_future  time_idx  forecast_step  \n",
       "103      False         1          -1567  \n",
       "104      False         2          -1566  \n",
       "105      False         3          -1565  \n",
       "106      False         4          -1564  \n",
       "107      False         5          -1563  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fc86167-f09e-4c14-a2e7-e7b8a1971436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts_id                     0\n",
       "date                      0\n",
       "sales                    16\n",
       "lag_sales_1              15\n",
       "lag_sales_2              14\n",
       "                         ..\n",
       "mean_sales_by_cluster     0\n",
       "std_sales_by_cluster      0\n",
       "is_future                 0\n",
       "time_idx                  0\n",
       "forecast_step             0\n",
       "Length: 155, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df[sales_df.ts_id == '1_0'].sort_values('date', ascending=False).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b170a89d-c4ad-42f8-8e42-5c0e599bd42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>lag_sales_1</th>\n",
       "      <th>lag_sales_2</th>\n",
       "      <th>lag_sales_3</th>\n",
       "      <th>lag_sales_4</th>\n",
       "      <th>lag_sales_5</th>\n",
       "      <th>lag_sales_6</th>\n",
       "      <th>lag_sales_7</th>\n",
       "      <th>...</th>\n",
       "      <th>std_sales_by_stateid_cityid</th>\n",
       "      <th>mean_sales_by_stateid_cluster</th>\n",
       "      <th>std_sales_by_stateid_cluster</th>\n",
       "      <th>mean_sales_by_cluster_bu</th>\n",
       "      <th>std_sales_by_cluster_bu</th>\n",
       "      <th>mean_sales_by_cluster</th>\n",
       "      <th>std_sales_by_cluster</th>\n",
       "      <th>is_future</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>forecast_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1584</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1583</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1582</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1581</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1580</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1579</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1578</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1577</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1576</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1575</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1574</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1573</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1572</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1571</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>True</td>\n",
       "      <td>1569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>1568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-07-29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>1567</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>1566</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>1_0</td>\n",
       "      <td>2017-07-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1662.976645</td>\n",
       "      <td>413.425163</td>\n",
       "      <td>998.959234</td>\n",
       "      <td>288.148076</td>\n",
       "      <td>626.985139</td>\n",
       "      <td>391.75253</td>\n",
       "      <td>950.365401</td>\n",
       "      <td>False</td>\n",
       "      <td>1565</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ts_id       date  sales  lag_sales_1  lag_sales_2  lag_sales_3  \\\n",
       "1686   1_0 2017-08-15    NaN          NaN          NaN          NaN   \n",
       "1685   1_0 2017-08-14    NaN          NaN          NaN          NaN   \n",
       "1684   1_0 2017-08-13    NaN          NaN          NaN          NaN   \n",
       "1683   1_0 2017-08-12    NaN          NaN          NaN          NaN   \n",
       "1682   1_0 2017-08-11    NaN          NaN          NaN          NaN   \n",
       "1681   1_0 2017-08-10    NaN          NaN          NaN          NaN   \n",
       "1680   1_0 2017-08-09    NaN          NaN          NaN          NaN   \n",
       "1679   1_0 2017-08-08    NaN          NaN          NaN          NaN   \n",
       "1678   1_0 2017-08-07    NaN          NaN          NaN          NaN   \n",
       "1677   1_0 2017-08-06    NaN          NaN          NaN          NaN   \n",
       "1676   1_0 2017-08-05    NaN          NaN          NaN          NaN   \n",
       "1675   1_0 2017-08-04    NaN          NaN          NaN          NaN   \n",
       "1674   1_0 2017-08-03    NaN          NaN          NaN          NaN   \n",
       "1673   1_0 2017-08-02    NaN          NaN          NaN          1.0   \n",
       "1672   1_0 2017-08-01    NaN          NaN          1.0          4.0   \n",
       "1671   1_0 2017-07-31    NaN          1.0          4.0          7.0   \n",
       "1670   1_0 2017-07-30    1.0          4.0          7.0          5.0   \n",
       "1669   1_0 2017-07-29    4.0          7.0          5.0          2.0   \n",
       "1668   1_0 2017-07-28    7.0          5.0          2.0         10.0   \n",
       "1667   1_0 2017-07-27    5.0          2.0         10.0          4.0   \n",
       "\n",
       "      lag_sales_4  lag_sales_5  lag_sales_6  lag_sales_7  ...  \\\n",
       "1686          NaN          NaN          NaN          NaN  ...   \n",
       "1685          NaN          NaN          NaN          NaN  ...   \n",
       "1684          NaN          NaN          NaN          NaN  ...   \n",
       "1683          NaN          NaN          NaN          NaN  ...   \n",
       "1682          NaN          NaN          NaN          NaN  ...   \n",
       "1681          NaN          NaN          NaN          NaN  ...   \n",
       "1680          NaN          NaN          NaN          NaN  ...   \n",
       "1679          NaN          NaN          NaN          NaN  ...   \n",
       "1678          NaN          NaN          NaN          NaN  ...   \n",
       "1677          NaN          NaN          NaN          1.0  ...   \n",
       "1676          NaN          NaN          1.0          4.0  ...   \n",
       "1675          NaN          1.0          4.0          7.0  ...   \n",
       "1674          1.0          4.0          7.0          5.0  ...   \n",
       "1673          4.0          7.0          5.0          2.0  ...   \n",
       "1672          7.0          5.0          2.0         10.0  ...   \n",
       "1671          5.0          2.0         10.0          4.0  ...   \n",
       "1670          2.0         10.0          4.0          0.0  ...   \n",
       "1669         10.0          4.0          0.0          8.0  ...   \n",
       "1668          4.0          0.0          8.0         10.0  ...   \n",
       "1667          0.0          8.0         10.0          4.0  ...   \n",
       "\n",
       "      std_sales_by_stateid_cityid  mean_sales_by_stateid_cluster  \\\n",
       "1686                  1662.976645                     413.425163   \n",
       "1685                  1662.976645                     413.425163   \n",
       "1684                  1662.976645                     413.425163   \n",
       "1683                  1662.976645                     413.425163   \n",
       "1682                  1662.976645                     413.425163   \n",
       "1681                  1662.976645                     413.425163   \n",
       "1680                  1662.976645                     413.425163   \n",
       "1679                  1662.976645                     413.425163   \n",
       "1678                  1662.976645                     413.425163   \n",
       "1677                  1662.976645                     413.425163   \n",
       "1676                  1662.976645                     413.425163   \n",
       "1675                  1662.976645                     413.425163   \n",
       "1674                  1662.976645                     413.425163   \n",
       "1673                  1662.976645                     413.425163   \n",
       "1672                  1662.976645                     413.425163   \n",
       "1671                  1662.976645                     413.425163   \n",
       "1670                  1662.976645                     413.425163   \n",
       "1669                  1662.976645                     413.425163   \n",
       "1668                  1662.976645                     413.425163   \n",
       "1667                  1662.976645                     413.425163   \n",
       "\n",
       "      std_sales_by_stateid_cluster  mean_sales_by_cluster_bu  \\\n",
       "1686                    998.959234                288.148076   \n",
       "1685                    998.959234                288.148076   \n",
       "1684                    998.959234                288.148076   \n",
       "1683                    998.959234                288.148076   \n",
       "1682                    998.959234                288.148076   \n",
       "1681                    998.959234                288.148076   \n",
       "1680                    998.959234                288.148076   \n",
       "1679                    998.959234                288.148076   \n",
       "1678                    998.959234                288.148076   \n",
       "1677                    998.959234                288.148076   \n",
       "1676                    998.959234                288.148076   \n",
       "1675                    998.959234                288.148076   \n",
       "1674                    998.959234                288.148076   \n",
       "1673                    998.959234                288.148076   \n",
       "1672                    998.959234                288.148076   \n",
       "1671                    998.959234                288.148076   \n",
       "1670                    998.959234                288.148076   \n",
       "1669                    998.959234                288.148076   \n",
       "1668                    998.959234                288.148076   \n",
       "1667                    998.959234                288.148076   \n",
       "\n",
       "      std_sales_by_cluster_bu  mean_sales_by_cluster  std_sales_by_cluster  \\\n",
       "1686               626.985139              391.75253            950.365401   \n",
       "1685               626.985139              391.75253            950.365401   \n",
       "1684               626.985139              391.75253            950.365401   \n",
       "1683               626.985139              391.75253            950.365401   \n",
       "1682               626.985139              391.75253            950.365401   \n",
       "1681               626.985139              391.75253            950.365401   \n",
       "1680               626.985139              391.75253            950.365401   \n",
       "1679               626.985139              391.75253            950.365401   \n",
       "1678               626.985139              391.75253            950.365401   \n",
       "1677               626.985139              391.75253            950.365401   \n",
       "1676               626.985139              391.75253            950.365401   \n",
       "1675               626.985139              391.75253            950.365401   \n",
       "1674               626.985139              391.75253            950.365401   \n",
       "1673               626.985139              391.75253            950.365401   \n",
       "1672               626.985139              391.75253            950.365401   \n",
       "1671               626.985139              391.75253            950.365401   \n",
       "1670               626.985139              391.75253            950.365401   \n",
       "1669               626.985139              391.75253            950.365401   \n",
       "1668               626.985139              391.75253            950.365401   \n",
       "1667               626.985139              391.75253            950.365401   \n",
       "\n",
       "      is_future  time_idx  forecast_step  \n",
       "1686       True      1584             16  \n",
       "1685       True      1583             15  \n",
       "1684       True      1582             14  \n",
       "1683       True      1581             13  \n",
       "1682       True      1580             12  \n",
       "1681       True      1579             11  \n",
       "1680       True      1578             10  \n",
       "1679       True      1577              9  \n",
       "1678       True      1576              8  \n",
       "1677       True      1575              7  \n",
       "1676       True      1574              6  \n",
       "1675       True      1573              5  \n",
       "1674       True      1572              4  \n",
       "1673       True      1571              3  \n",
       "1672       True      1570              2  \n",
       "1671       True      1569              1  \n",
       "1670      False      1568              0  \n",
       "1669      False      1567             -1  \n",
       "1668      False      1566             -2  \n",
       "1667      False      1565             -3  \n",
       "\n",
       "[20 rows x 155 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df[sales_df.ts_id == '1_0'].sort_values('date', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f4ba1-97d0-49f7-8f43-7b60cb0d5159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59df06-5bfe-4f47-93c4-641d5cc76e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e61a3cc-7684-400f-97a1-08e5c5a671f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast",
   "language": "python",
   "name": "forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
